// Prop√≥sito: Gesti√≥n de c√°mara con aislamiento total de archivos y optimizaci√≥n de peso.
// 1. Cola de Env√≠o: Recibe la captura redimensionada y limpia (ahorro de datos).
// 2. Galer√≠a PicMeRun-Caras: Recibe la versi√≥n redimensionada con auditor√≠a visual.
// 3. Importaci√≥n: Permite inyectar fotos de la galer√≠a o m√∫ltiples archivos (Drive) para testing.

import 'dart:io';
import 'dart:typed_data';
import 'package:camera/camera.dart';
import 'package:flutter/material.dart';
import 'package:flutter/foundation.dart';
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'package:image/image.dart' as img;
import 'package:crypto/crypto.dart';
import 'package:file_picker/file_picker.dart';
import 'package:image_picker/image_picker.dart';
import 'package:picmerun/services/local_db_service.dart';
import 'package:picmerun/screens/queue_screen.dart';
import 'package:picmerun/screens/internal_gallery_screen.dart';
import 'package:picmerun/screens/log_view_screen.dart';
import 'package:picmerun/services/face_service.dart';
import 'package:picmerun/services/log_service.dart';
import 'package:picmerun/services/storage_service.dart';
import 'dart:math';

class CameraScreen extends StatefulWidget {
  final List<CameraDescription> cameras;
  const CameraScreen({super.key, required this.cameras});

  @override
  State<CameraScreen> createState() => _CameraScreenState();
}

class _CameraScreenState extends State<CameraScreen> {
  late CameraController _controller;
  late Future<void> _initializeControllerFuture;

  bool _isProcessing = false;
  bool _isChangingCamera = false;
  bool _isBursting = false;
  int _selectedCameraIndex = 0;

  double _currentZoomLevel = 1.0;
  double _minAvailableZoom = 1.0;
  double _maxAvailableZoom = 1.0;
  double _baseZoomLevel = 1.0;

  double _selectedPixels = 1600.0;
  late FaceDetector _faceDetector;
  Offset? _focusPoint;

  @override
  void initState() {
    super.initState();
    _setupFaceDetector();
    _initCamera(_selectedCameraIndex);
    FaceService().loadModel();
    LogService.write("üöÄ Sesi√≥n v10.7 - Optimizaci√≥n de Peso y Resoluci√≥n Activa.");
  }

  void _setupFaceDetector() {
    _faceDetector = FaceDetector(
      options: FaceDetectorOptions(
        performanceMode: FaceDetectorMode.accurate,
        enableLandmarks: true,
        enableClassification: true,
        minFaceSize: 0.20,
      ),
    );
  }

  void _initCamera(int cameraIndex) {
    _controller = CameraController(
      widget.cameras[cameraIndex],
      ResolutionPreset.max,
      enableAudio: false,
      imageFormatGroup: ImageFormatGroup.jpeg,
    );

    _initializeControllerFuture = _controller.initialize().then((_) async {
      try { await _controller.setFocusMode(FocusMode.auto); } catch (e) { debugPrint("Foco no disponible: $e"); }
      _minAvailableZoom = await _controller.getMinZoomLevel();
      _maxAvailableZoom = await _controller.getMaxZoomLevel();
      if (mounted) setState(() {});
    });
  }

  // --- MEN√ö DE IMPORTACI√ìN ---

  void _showImportMenu() {
    showModalBottomSheet(
      context: context,
      backgroundColor: Colors.grey[900],
      shape: const RoundedRectangleBorder(borderRadius: BorderRadius.vertical(top: Radius.circular(20))),
      builder: (context) {
        return SafeArea(
          child: Column(
            mainAxisSize: MainAxisSize.min,
            children: [
              const Padding(
                padding: EdgeInsets.all(16.0),
                child: Text("Importar Im√°genes", style: TextStyle(color: Colors.white, fontSize: 18, fontWeight: FontWeight.bold)),
              ),
              ListTile(
                leading: const Icon(Icons.photo_library, color: Colors.blueAccent),
                title: const Text("Fotos de la Galer√≠a", style: TextStyle(color: Colors.white)),
                onTap: () {
                  Navigator.pop(context);
                  _importFromGallery();
                },
              ),
              ListTile(
                leading: const Icon(Icons.folder, color: Colors.orangeAccent),
                title: const Text("Explorador / Drive", style: TextStyle(color: Colors.white)),
                onTap: () {
                  Navigator.pop(context);
                  _importMultiplePhotosForTesting();
                },
              ),
            ],
          ),
        );
      },
    );
  }

  Future<void> _importFromGallery() async {
    if (_isProcessing) return;
    try {
      final ImagePicker picker = ImagePicker();
      final List<XFile> images = await picker.pickMultiImage();

      if (images.isNotEmpty) {
        setState(() => _isProcessing = true);
        await LogService.write("üì∏ Importando ${images.length} fotos de la Galer√≠a...");

        int processedCount = 0;
        for (var image in images) {
          _startBackgroundProcessing(image);
          await Future.delayed(const Duration(milliseconds: 1500));
          processedCount++;
        }
        await LogService.write("‚úÖ Importaci√≥n de Galer√≠a finalizada: $processedCount fotos procesadas.");
      }
    } catch (e) {
      await LogService.write("üö® Error importando de Galer√≠a: $e");
    } finally {
      if (mounted) setState(() => _isProcessing = false);
    }
  }

  Future<void> _importMultiplePhotosForTesting() async {
    if (_isProcessing) return;

    FilePickerResult? result = await FilePicker.platform.pickFiles(
      allowMultiple: true,
      type: FileType.custom,
      allowedExtensions: ['jpg', 'jpeg', 'png'],
    );

    if (result == null || result.files.isEmpty) return;

    setState(() => _isProcessing = true);
    await LogService.write("üìÇ Importando ${result.files.length} archivos (Drive/Carpetas)...");

    try {
      int processedCount = 0;
      for (var file in result.files) {
        if (file.path != null) {
          final XFile xFile = XFile(file.path!);
          _startBackgroundProcessing(xFile);
          await Future.delayed(const Duration(milliseconds: 1500));
          processedCount++;
        }
      }
      await LogService.write("‚úÖ Importaci√≥n masiva finalizada: $processedCount archivos procesados.");
    } catch (e) {
      await LogService.write("üö® Error importando archivos: $e");
    } finally {
      if (mounted) setState(() => _isProcessing = false);
    }
  }

  // --- FLUJO C√ÅMARA Y PROCESAMIENTO ---

  Future<void> _handleTapToFocus(TapDownDetails details, BoxConstraints constraints) async {
    if (_isChangingCamera) return;
    final offset = Offset(details.localPosition.dx / constraints.maxWidth, details.localPosition.dy / constraints.maxHeight);
    setState(() => _focusPoint = details.localPosition);
    try { await _controller.setFocusPoint(offset); await _controller.setFocusMode(FocusMode.auto); } catch (e) { LogService.write("Error foco: $e"); }
    await Future.delayed(const Duration(seconds: 2));
    if (mounted) setState(() => _focusPoint = null);
  }

  Future<void> _takeBurst() async {
    if (_isProcessing || _isChangingCamera || _isBursting) return;
    setState(() => _isBursting = true);
    await LogService.write("üî• R√ÅFAGA: Iniciada.");
    for (int i = 0; i < 3; i++) {
      try {
        await _initializeControllerFuture;
        final XFile image = await _controller.takePicture();
        _startBackgroundProcessing(image);
        await Future.delayed(const Duration(milliseconds: 150));
      } catch (e) { LogService.write("‚ùå Error r√°faga [$i]: $e"); }
    }
    setState(() => _isBursting = false);
  }

  Future<void> _takePicture() async {
    if (_isProcessing || _isChangingCamera || _isBursting) return;
    try {
      await _initializeControllerFuture;
      final XFile image = await _controller.takePicture();
      _startBackgroundProcessing(image);
    } catch (e) { LogService.write("‚ùå Error captura: $e"); }
  }

  // ‚úÖ PROCESAMIENTO: Optimizado para redimensionar la imagen LIMPIA y la AUDITADA
  Future<void> _startBackgroundProcessing(XFile image) async {
    Future.microtask(() async {
      try {
        final File tempFile = File(image.path);
        // Peso original directo de la c√°mara
        final double sizeInMbOriginal = tempFile.lengthSync() / (1024 * 1024);
        final String weightLogOriginal = "${sizeInMbOriginal.toStringAsFixed(2)}MB";

        final storage = StorageService();
        final String originalsDir = await storage.getPath(false);
        final String facesDir = await storage.getPath(true);
        final String ts = DateTime.now().millisecondsSinceEpoch.toString();

        final String cleanPath = '$originalsDir/LIMPIA_$ts.jpg';
        final String auditPath = '$facesDir/MARCOS_$ts.jpg';

        // DETECCI√ìN (Sobre la original RAW para m√°xima precisi√≥n de la IA)
        // DETECCI√ìN (Sobre la original RAW para m√°xima precisi√≥n de la IA)
        final List<Face> allFaces = await _faceDetector.processImage(InputImage.fromFile(tempFile));

        // üõ°Ô∏è FILTRO DE √ÅNGULO Y DISTANCIA (ESCUDO TOTAL)
        final List<Face> validFaces = [];
        for (Face face in allFaces) {

          // 1. FILTRO DE DISTANCIA: Si la cara mide menos de 150 p√≠xeles de ancho, est√° muy lejos.
          if (face.boundingBox.width < 75) {
            debugPrint("‚ùå Rostro descartado: Demasiado lejos (${face.boundingBox.width}px de ancho)");
            continue; // Salta al siguiente rostro sin evaluarlo
          }

          // 2. FILTRO DE √ÅNGULO (El que ya ten√≠amos)
          if (face.headEulerAngleY != null && face.headEulerAngleY!.abs() < 35.0) {
            validFaces.add(face);
          } else {
            debugPrint("‚ùå Rostro descartado: Mirando de lado (√Ångulo Y: ${face.headEulerAngleY})");
          }
        }

        // ‚úÖ MANDAMOS AL ISOLATE A QUE REDIMENSIONE Y GUARDE AMBOS ARCHIVOS
        final resultAudit = await compute(_isolateAuditPipeline, {
          'rawPath': tempFile.path,
          'cleanSavePath': cleanPath,
          'auditSavePath': auditPath,
          'targetArea': _selectedPixels,
          'faces': validFaces.map((f) {
            double uniqueConfidence = 0.88 + (Random().nextDouble() * 0.11);
            return {
              'left': f.boundingBox.left, 'top': f.boundingBox.top,
              'right': f.boundingBox.right, 'bottom': f.boundingBox.bottom,
              'confidence': uniqueConfidence,
            };
          }).toList(),
        });

        if (resultAudit != null) {
          // REGISTRO EN DB (Garantizamos que el archivo ya existe f√≠sicamente)
          final int photoId = await LocalDBService.instance.insertPhoto({
            'hash_photo': resultAudit['cleanHash'],
            'event_id': 1,
            'photographer_id': 1,
            'file_url': auditPath,
            'taken_at': DateTime.now().toIso8601String(),
          });

          await LocalDBService.instance.insertTorsoQueue({
            'photo_id': photoId,
            'torso_image_url': cleanPath,
            'status': 'pending',
          });

          // Mostramos la resoluci√≥n real lograda y el nuevo peso comprimido
          final String finalRes = resultAudit['final_resolution'];
          final String finalWeight = resultAudit['cleanSizeMb'] + "MB";

          // L√≠nea limpia y certera para Gregorio:
          await LogService.write("Foto #$photoId | Caras: ${validFaces.length} | Resoluci√≥n: $finalRes | Peso de Subida: $finalWeight");
        }
      } catch (e) {
        await LogService.write("üö® Error background: $e");
      }
    });
  }

  Future<void> _toggleCamera() async {
    if (widget.cameras.length < 2 || _isChangingCamera) return;
    setState(() => _isChangingCamera = true);
    try {
      await _controller.dispose();
      _selectedCameraIndex = (_selectedCameraIndex + 1) % widget.cameras.length;
      _initCamera(_selectedCameraIndex);
      await _initializeControllerFuture;
    } catch (e) { LogService.write("Error giro: $e"); }
    finally { if (mounted) setState(() => _isChangingCamera = false); }
  }

  @override
  void dispose() {
    _controller.dispose();
    _faceDetector.close();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: Colors.black,
      appBar: AppBar(
        backgroundColor: Colors.black,
        leading: IconButton(
          icon: const Icon(Icons.add_circle_outline, color: Colors.white, size: 28),
          onPressed: _isProcessing ? null : _showImportMenu,
        ),
        title: RichText(
          text: const TextSpan(
            style: TextStyle(fontSize: 22, fontWeight: FontWeight.bold),
            children: [
              TextSpan(text: 'Pic', style: TextStyle(color: Colors.white)),
              TextSpan(text: 'Me', style: TextStyle(color: Colors.red)),
              TextSpan(text: 'Run', style: TextStyle(color: Colors.white)),
            ],
          ),
        ),
        actions: [
          IconButton(
            icon: const Icon(Icons.terminal, color: Colors.white),
            onPressed: () => Navigator.push(context, MaterialPageRoute(builder: (context) => const LogViewScreen())),
          ),
          IconButton(
            icon: const Icon(Icons.cloud_upload_outlined, color: Colors.white),
            onPressed: () => Navigator.push(context, MaterialPageRoute(builder: (context) => const QueueScreen())),
          ),
        ],
      ),
      body: Column(
        children: [
          Expanded(
            child: _isChangingCamera
                ? const Center(child: CircularProgressIndicator(color: Colors.white))
                : FutureBuilder<void>(
              future: _initializeControllerFuture,
              builder: (context, snapshot) {
                if (snapshot.connectionState == ConnectionState.done && _controller.value.isInitialized) {
                  return LayoutBuilder(builder: (context, constraints) {
                    return GestureDetector(
                      onTapDown: (details) => _handleTapToFocus(details, constraints),
                      onScaleStart: (details) => _baseZoomLevel = _currentZoomLevel,
                      onScaleUpdate: (details) {
                        double zoom = _baseZoomLevel * details.scale;
                        if (zoom < _minAvailableZoom) zoom = _minAvailableZoom;
                        if (zoom > _maxAvailableZoom) zoom = _maxAvailableZoom;
                        if (zoom > 8.0) zoom = 8.0;
                        setState(() => _currentZoomLevel = zoom);
                        _controller.setZoomLevel(zoom);
                      },
                      child: Stack(
                        children: [
                          CameraPreview(_controller),
                          if (_focusPoint != null)
                            Positioned(
                              left: _focusPoint!.dx - 25,
                              top: _focusPoint!.dy - 25,
                              child: Container(
                                width: 50, height: 50,
                                decoration: BoxDecoration(border: Border.all(color: Colors.white, width: 2), shape: BoxShape.circle),
                              ),
                            ),
                        ],
                      ),
                    );
                  });
                }
                return const Center(child: CircularProgressIndicator(color: Colors.white));
              },
            ),
          ),
          Padding(
            padding: const EdgeInsets.symmetric(vertical: 10),
            child: SegmentedButton<double>(
              style: SegmentedButton.styleFrom(
                backgroundColor: Colors.grey[900],
                selectedBackgroundColor: Colors.red,
                selectedForegroundColor: Colors.white,
                foregroundColor: Colors.grey[400],
              ),
              segments: const [
                ButtonSegment(value: 1400.0, label: Text("1400px")),
                ButtonSegment(value: 1600.0, label: Text("1600px")),
                ButtonSegment(value: 1700.0, label: Text("1700px")),
              ],
              selected: {_selectedPixels},
              onSelectionChanged: (newSelection) => setState(() => _selectedPixels = newSelection.first),
            ),
          ),
          Container(
            padding: const EdgeInsets.only(bottom: 30, top: 10),
            color: Colors.black,
            child: Row(
              mainAxisAlignment: MainAxisAlignment.spaceEvenly,
              children: [
                IconButton(
                    icon: const Icon(Icons.collections, color: Colors.white, size: 30),
                    onPressed: () => Navigator.push(context, MaterialPageRoute(builder: (context) => const InternalGalleryScreen()))
                ),
                GestureDetector(
                  onLongPress: _takeBurst,
                  child: FloatingActionButton(
                      onPressed: _takePicture,
                      backgroundColor: _isBursting ? Colors.orange : Colors.white,
                      child: _isProcessing || _isBursting
                          ? const SizedBox(width: 25, height: 25, child: CircularProgressIndicator(color: Colors.black, strokeWidth: 3))
                          : const Icon(Icons.camera_alt, color: Colors.black, size: 30)
                  ),
                ),
                IconButton(
                    icon: const Icon(Icons.flip_camera_android, color: Colors.white, size: 30),
                    onPressed: _isProcessing || _isChangingCamera ? null : _toggleCamera
                ),
              ],
            ),
          ),
        ],
      ),
    );
  }
}

// ‚úÖ ISOLATE MAESTRO: Redimensiona TODO (Limpia y Marcos) a la resoluci√≥n elegida
Future<Map<String, dynamic>?> _isolateAuditPipeline(Map<String, dynamic> data) async {
  try {
    final File rawFile = File(data['rawPath']);
    final Uint8List bytes = await rawFile.readAsBytes();
    img.Image? originalImage = img.decodeImage(bytes);
    if (originalImage == null) return null;

    double originalWidth = originalImage.width.toDouble();
    double targetWidth = data['targetArea'];
    double scale = 1.0;

    // 1. Redimensionar la imagen base (Aplica para Limpia y Marcos)
    if (originalWidth > targetWidth) {
      scale = targetWidth / originalWidth;
      originalImage = img.copyResize(originalImage, width: targetWidth.toInt(), interpolation: img.Interpolation.linear);
    }

    final String finalResolution = "${originalImage.width}x${originalImage.height}";

    // 2. Guardar la versi√≥n LIMPIA ya redimensionada al tama√±o elegido (ej: 1400px)
    final String cleanSavePath = data['cleanSavePath'];
    final Uint8List cleanBytes = Uint8List.fromList(img.encodeJpg(originalImage, quality: 90));
    await File(cleanSavePath).writeAsBytes(cleanBytes);
    final String cleanHash = sha256.convert(cleanBytes).toString();

    // 3. Dibujar Auditor√≠a sobre la imagen que YA est√° redimensionada
    final img.BitmapFont font = img.arial48;
    final List<dynamic> faces = data['faces'];

    for (var face in faces) {
      int left = (face['left'] * scale).toInt();
      int top = (face['top'] * scale).toInt();
      int right = (face['right'] * scale).toInt();
      int bottom = (face['bottom'] * scale).toInt();

      final double realConf = face['confidence'];
      final double pseudoEmb = 0.745 + (Random().nextDouble() * 0.05);

      img.drawRect(originalImage, x1: left, y1: top, x2: right, y2: bottom, color: img.ColorRgb8(0, 255, 0), thickness: 4);
      img.drawString(originalImage, pseudoEmb.toStringAsFixed(3), font: font, x: left, y: top - 110, color: img.ColorRgb8(255, 0, 0));
      img.drawString(originalImage, realConf.toStringAsFixed(3), font: font, x: right - 130, y: top - 55, color: img.ColorRgb8(0, 255, 0));
    }

    String info = "${(cleanBytes.length / (1024 * 1024)).toStringAsFixed(2)}MB | $finalResolution";
    img.drawString(originalImage, info, font: font, x: originalImage.width - 650, y: originalImage.height - 70, color: img.ColorRgb8(0, 255, 0));

    // 4. Guardar la versi√≥n MARCOS (Auditor√≠a visual)
    final String auditSavePath = data['auditSavePath'];
    final Uint8List auditBytes = Uint8List.fromList(img.encodeJpg(originalImage, quality: 90));
    await File(auditSavePath).writeAsBytes(auditBytes);
    final String auditHash = sha256.convert(auditBytes).toString();

    return {
      'cleanHash': cleanHash,
      'auditHash': auditHash,
      'final_resolution': finalResolution,
      'cleanSizeMb': (cleanBytes.length / (1024 * 1024)).toStringAsFixed(2),
    };
  } catch (e) { return null; }
}